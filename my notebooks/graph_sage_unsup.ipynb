{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "source: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_sage_unsup_ppi.py"
      ],
      "metadata": {
        "id": "CGsiRmj6n6gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# solved import problem with help of https://gist.github.com/ameya98/b193856171d11d37ada46458f60e73e7 \n",
        "\n",
        "\n",
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCQiO0lKn_eX",
        "outputId": "f6a0953d-a761-4e59-b2a6-459d4c7fc132"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 1.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=d2a4157a0c7acb8caec499d6868890cd5adb10b815604f2660185a7f2d47219d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.datasets import PPI\n",
        "from torch_geometric.loader import DataLoader, LinkNeighborLoader\n",
        "from torch_geometric.nn import GraphSAGE"
      ],
      "metadata": {
        "id": "WKgZprRcn_ZX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = osp.join('..', 'data', 'PPI')\n",
        "train_dataset = PPI(path, split='train')\n",
        "val_dataset = PPI(path, split='val')\n",
        "test_dataset = PPI(path, split='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCOTyAd6n_YU",
        "outputId": "d729e4e0-a062-44d3-c932-511aee50e6ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.dgl.ai/dataset/ppi.zip\n",
            "Extracting ../data/PPI/ppi.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group all training graphs into a single graph to perform sampling:\n",
        "train_data = Batch.from_data_list(train_dataset)\n",
        "loader = LinkNeighborLoader(train_data, batch_size=2048, shuffle=True,\n",
        "                            neg_sampling_ratio=0.5, num_neighbors=[10, 10],\n",
        "                            num_workers=6, persistent_workers=True)\n",
        "\n",
        "# Evaluation loaders (one datapoint corresponds to a graph)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GraphSAGE(\n",
        "    in_channels=train_dataset.num_features,\n",
        "    hidden_channels=64,\n",
        "    num_layers=2,\n",
        "    out_channels=64,\n",
        ").to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU6hjtW1oOV2",
        "outputId": "dc9a4a44-4bec-41a3-ab4b-2186752494c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for data in tqdm.tqdm(loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        h = model(data.x, data.edge_index)\n",
        "\n",
        "        h_src = h[data.edge_label_index[0]]\n",
        "        h_dst = h[data.edge_label_index[1]]\n",
        "        link_pred = (h_src * h_dst).sum(dim=-1)  # Inner product.\n",
        "\n",
        "        loss = F.binary_cross_entropy_with_logits(link_pred, data.edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss) * link_pred.numel()\n",
        "        total_examples += link_pred.numel()\n",
        "\n",
        "    return total_loss / total_examples"
      ],
      "metadata": {
        "id": "SSF_PdWaoOZQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def encode(loader):\n",
        "    model.eval()\n",
        "\n",
        "    xs, ys = [], []\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        xs.append(model(data.x, data.edge_index).cpu())\n",
        "        ys.append(data.y.cpu())\n",
        "    return torch.cat(xs, dim=0), torch.cat(ys, dim=0)"
      ],
      "metadata": {
        "id": "lQG1CqgToUus"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    # Train classifier on training set:\n",
        "    x, y = encode(train_loader)\n",
        "\n",
        "    clf = MultiOutputClassifier(SGDClassifier(loss='log', penalty='l2'))\n",
        "    clf.fit(x, y)\n",
        "\n",
        "    train_f1 = f1_score(y, clf.predict(x), average='micro')\n",
        "\n",
        "    # Evaluate on validation set:\n",
        "    x, y = encode(val_loader)\n",
        "    val_f1 = f1_score(y, clf.predict(x), average='micro')\n",
        "\n",
        "    # Evaluate on test set:\n",
        "    x, y = encode(test_loader)\n",
        "    test_f1 = f1_score(y, clf.predict(x), average='micro')\n",
        "\n",
        "    return train_f1, val_f1, test_f1"
      ],
      "metadata": {
        "id": "M5uCzckLoXJ1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJudHEhOn3WM"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, 6):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
        "    train_f1, val_f1, test_f1 = test()\n",
        "    print(f'Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}, '\n",
        "          f'Test F1: {test_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check more things:"
      ],
      "metadata": {
        "id": "5PmbvIRXormi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Batch.from_data_list(train_dataset)\n",
        "loader = LinkNeighborLoader(train_data, batch_size=2048, shuffle=True,\n",
        "                            neg_sampling_ratio=0.5, num_neighbors=[10, 10],\n",
        "                            num_workers=6, persistent_workers=True)\n",
        "\n",
        "# Evaluation loaders (one datapoint corresponds to a graph)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YOhUrEion0D",
        "outputId": "96172ce7-d1e8-404f-87c7-bfb8ee76f40e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PPI(2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEYiNRSjovRa",
        "outputId": "c1346a3f-39b2-45bb-957f-65080636ec32"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBatch(x=[44906, 50], edge_index=[2, 1226368], y=[44906, 121], batch=[44906], ptr=[21])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = Batch.from_data_list(test_dataset)"
      ],
      "metadata": {
        "id": "-XFW4r30qhbz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbvlWI5Yqo0q",
        "outputId": "83edc48f-205c-447f-d7d2-831728c8f097"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBatch(x=[5524, 50], edge_index=[2, 161976], y=[5524, 121], batch=[5524], ptr=[3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ANNm7OrsqxfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}