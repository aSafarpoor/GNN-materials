{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "edited lightgcn_pyg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpB61nHx24q9",
        "outputId": "e718f316-03d4-4cc5-ece4-c6d95732f201"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 4.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 3.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=1a9847fdce5a6f97922132653769ec3f4701ac1540c3214dfa15a627e5c5ef1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.1.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxoenua1-u5r"
      },
      "source": [
        "# # Install required packages.\n",
        "# %%capture\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "# !pip install torch-geometric\n",
        "# !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "# !pip install -U -q PyDrive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive"
      ],
      "metadata": {
        "id": "J5JAMtt-28O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4edc3ca-1072-47bf-eb0a-bee7992aae34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkNAZvtNQ6R"
      },
      "source": [
        "# Implementing a Recommender System using LightGCN\n",
        "\n",
        "In this colab, we explain how to set up a graph recommender system using the [LighGCN](https://arxiv.org/abs/2002.02126) model. Specifically, we apply LightGCN to a movie recommendation task using [PyTorch](https://pytorch.org/) and [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/).\n",
        "\n",
        "We use the [MovieLens](https://grouplens.org/datasets/movielens/) (*small*) dataset which has 100,000 ratings applied to 9,000 movies by 600 users. \n",
        "\n",
        "Our implementation was inspired by the following documentation and repositories:\n",
        "- https://github.com/gusye1234/LightGCN-PyTorch\n",
        "- https://www.kaggle.com/dipanjandas96/lightgcn-pytorch-from-scratch\n",
        "- https://pytorch-geometric.readthedocs.io/en/latest/notes/load_csv.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZ6-zPxPklE"
      },
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "We load the dataset and set ratings >=4 on a 0.5 ~ 5 scale as an edge between users and movies.\n",
        "\n",
        "We split the edges of the graph using a 80/10/10 train/validation/test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cRC_IazQ4Oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcfe914-5be3-4928-ea0e-c8d5059f8dd4"
      },
      "source": [
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2P3zYR8Q8EX"
      },
      "source": [
        "# load user and movie nodes\n",
        "def load_node_csv(path, index_col):\n",
        "    \"\"\"Loads csv containing node information\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        index_col (str): column name of index column\n",
        "\n",
        "    Returns:\n",
        "        dict: mapping of csv row to node id\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, index_col=index_col)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "    return mapping\n",
        "\n",
        "\n",
        "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
        "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJzQlxSRDEq"
      },
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        src_index_col (str): column name of users\n",
        "        src_mapping (dict): mapping between row number and user id\n",
        "        dst_index_col (str): column name of items\n",
        "        dst_mapping (dict): mapping between row number and item id\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    edge_index = None\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "\n",
        "    return torch.tensor(edge_index)\n",
        "\n",
        "\n",
        "edge_index = load_edge_csv(\n",
        "    rating_path,\n",
        "    src_index_col='userId',\n",
        "    src_mapping=user_mapping,\n",
        "    dst_index_col='movieId',\n",
        "    dst_mapping=movie_mapping,\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=4,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIueYZfaT6_H"
      },
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5yKILBJUAN6"
      },
      "source": [
        "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices(\n",
        "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "# Implementing LightGCN\n",
        "\n",
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "source": [
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v4A3Ek4TE02"
      },
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6_741LlTMwI"
      },
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "source": [
        "# define contants\n",
        "ITERATIONS = 10000\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 20\n",
        "LAMBDA = 1e-6"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49JDkBtKTfE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4aa095-1650-4fd7-eea5-ba753fd7c492"
      },
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYjrDp1w-hiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8259d69-f584-4727-8843-55893b0e4f98"
      },
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        BATCH_SIZE, train_edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/10000] train_loss: -0.69104, val_loss: -0.68382, val_recall@20: 0.00114, val_precision@20: 0.0009, val_ndcg@20: 0.00151\n",
            "[Iteration 200/10000] train_loss: -0.69789, val_loss: -0.68874, val_recall@20: 0.03942, val_precision@20: 0.0142, val_ndcg@20: 0.02778\n",
            "[Iteration 400/10000] train_loss: -0.85116, val_loss: -0.80949, val_recall@20: 0.13734, val_precision@20: 0.04141, val_ndcg@20: 0.10111\n",
            "[Iteration 600/10000] train_loss: -1.68569, val_loss: -1.46229, val_recall@20: 0.14142, val_precision@20: 0.0443, val_ndcg@20: 0.10454\n",
            "[Iteration 800/10000] train_loss: -3.38243, val_loss: -2.78711, val_recall@20: 0.14677, val_precision@20: 0.0453, val_ndcg@20: 0.10636\n",
            "[Iteration 1000/10000] train_loss: -5.21451, val_loss: -4.41163, val_recall@20: 0.14825, val_precision@20: 0.04593, val_ndcg@20: 0.10694\n",
            "[Iteration 1200/10000] train_loss: -7.26679, val_loss: -6.23634, val_recall@20: 0.14861, val_precision@20: 0.04638, val_ndcg@20: 0.10723\n",
            "[Iteration 1400/10000] train_loss: -10.02998, val_loss: -8.08498, val_recall@20: 0.14946, val_precision@20: 0.04593, val_ndcg@20: 0.10708\n",
            "[Iteration 1600/10000] train_loss: -12.68537, val_loss: -10.08548, val_recall@20: 0.15023, val_precision@20: 0.04602, val_ndcg@20: 0.1071\n",
            "[Iteration 1800/10000] train_loss: -14.30132, val_loss: -11.88368, val_recall@20: 0.15223, val_precision@20: 0.04675, val_ndcg@20: 0.10894\n",
            "[Iteration 2000/10000] train_loss: -16.97552, val_loss: -14.06224, val_recall@20: 0.15423, val_precision@20: 0.0472, val_ndcg@20: 0.10786\n",
            "[Iteration 2200/10000] train_loss: -19.03506, val_loss: -16.00992, val_recall@20: 0.15352, val_precision@20: 0.04684, val_ndcg@20: 0.10616\n",
            "[Iteration 2400/10000] train_loss: -22.23064, val_loss: -17.96294, val_recall@20: 0.15425, val_precision@20: 0.04702, val_ndcg@20: 0.10681\n",
            "[Iteration 2600/10000] train_loss: -23.64167, val_loss: -19.80169, val_recall@20: 0.15347, val_precision@20: 0.04675, val_ndcg@20: 0.1065\n",
            "[Iteration 2800/10000] train_loss: -27.84503, val_loss: -21.66088, val_recall@20: 0.15333, val_precision@20: 0.04656, val_ndcg@20: 0.10707\n",
            "[Iteration 3000/10000] train_loss: -28.42748, val_loss: -23.71171, val_recall@20: 0.15343, val_precision@20: 0.04675, val_ndcg@20: 0.10734\n",
            "[Iteration 3200/10000] train_loss: -30.89888, val_loss: -25.36014, val_recall@20: 0.15323, val_precision@20: 0.04665, val_ndcg@20: 0.10719\n",
            "[Iteration 3400/10000] train_loss: -33.83561, val_loss: -26.96137, val_recall@20: 0.15321, val_precision@20: 0.04656, val_ndcg@20: 0.10738\n",
            "[Iteration 3600/10000] train_loss: -36.06585, val_loss: -28.96785, val_recall@20: 0.15363, val_precision@20: 0.04684, val_ndcg@20: 0.10763\n",
            "[Iteration 3800/10000] train_loss: -37.69327, val_loss: -30.32189, val_recall@20: 0.15411, val_precision@20: 0.04665, val_ndcg@20: 0.10768\n",
            "[Iteration 4000/10000] train_loss: -39.86345, val_loss: -31.81046, val_recall@20: 0.15355, val_precision@20: 0.04684, val_ndcg@20: 0.10755\n",
            "[Iteration 4200/10000] train_loss: -41.84562, val_loss: -33.38377, val_recall@20: 0.15319, val_precision@20: 0.04656, val_ndcg@20: 0.10721\n",
            "[Iteration 4400/10000] train_loss: -43.55392, val_loss: -34.65502, val_recall@20: 0.15364, val_precision@20: 0.04693, val_ndcg@20: 0.10773\n",
            "[Iteration 4600/10000] train_loss: -43.45072, val_loss: -36.13287, val_recall@20: 0.15362, val_precision@20: 0.04684, val_ndcg@20: 0.10733\n",
            "[Iteration 4800/10000] train_loss: -44.22092, val_loss: -37.63501, val_recall@20: 0.1537, val_precision@20: 0.04684, val_ndcg@20: 0.10732\n",
            "[Iteration 5000/10000] train_loss: -45.49595, val_loss: -38.41198, val_recall@20: 0.15366, val_precision@20: 0.04684, val_ndcg@20: 0.10733\n",
            "[Iteration 5200/10000] train_loss: -48.91623, val_loss: -39.91332, val_recall@20: 0.1537, val_precision@20: 0.04684, val_ndcg@20: 0.10744\n",
            "[Iteration 5400/10000] train_loss: -50.04998, val_loss: -41.35878, val_recall@20: 0.15355, val_precision@20: 0.04684, val_ndcg@20: 0.10755\n",
            "[Iteration 5600/10000] train_loss: -51.04178, val_loss: -42.57621, val_recall@20: 0.15354, val_precision@20: 0.04675, val_ndcg@20: 0.10729\n",
            "[Iteration 5800/10000] train_loss: -54.69475, val_loss: -43.42221, val_recall@20: 0.15354, val_precision@20: 0.04675, val_ndcg@20: 0.10725\n",
            "[Iteration 6000/10000] train_loss: -55.01542, val_loss: -43.98056, val_recall@20: 0.15372, val_precision@20: 0.04693, val_ndcg@20: 0.10731\n",
            "[Iteration 6200/10000] train_loss: -55.26775, val_loss: -45.43793, val_recall@20: 0.15372, val_precision@20: 0.04693, val_ndcg@20: 0.10718\n",
            "[Iteration 6400/10000] train_loss: -56.46704, val_loss: -46.2066, val_recall@20: 0.15363, val_precision@20: 0.04684, val_ndcg@20: 0.10722\n",
            "[Iteration 6600/10000] train_loss: -56.76429, val_loss: -48.03373, val_recall@20: 0.15363, val_precision@20: 0.04684, val_ndcg@20: 0.10724\n",
            "[Iteration 6800/10000] train_loss: -57.46382, val_loss: -48.22942, val_recall@20: 0.15369, val_precision@20: 0.04684, val_ndcg@20: 0.10729\n",
            "[Iteration 7000/10000] train_loss: -60.19389, val_loss: -48.96323, val_recall@20: 0.15369, val_precision@20: 0.04684, val_ndcg@20: 0.10728\n",
            "[Iteration 7200/10000] train_loss: -60.53769, val_loss: -49.26611, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10735\n",
            "[Iteration 7400/10000] train_loss: -62.80291, val_loss: -50.81091, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10735\n",
            "[Iteration 7600/10000] train_loss: -63.95995, val_loss: -51.27157, val_recall@20: 0.15356, val_precision@20: 0.04665, val_ndcg@20: 0.10729\n",
            "[Iteration 7800/10000] train_loss: -61.80553, val_loss: -51.53067, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10733\n",
            "[Iteration 8000/10000] train_loss: -65.25693, val_loss: -52.32737, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10734\n",
            "[Iteration 8200/10000] train_loss: -65.58345, val_loss: -52.65794, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10733\n",
            "[Iteration 8400/10000] train_loss: -66.30259, val_loss: -54.24631, val_recall@20: 0.15362, val_precision@20: 0.04665, val_ndcg@20: 0.10723\n",
            "[Iteration 8600/10000] train_loss: -66.99526, val_loss: -54.91232, val_recall@20: 0.15362, val_precision@20: 0.04665, val_ndcg@20: 0.1072\n",
            "[Iteration 8800/10000] train_loss: -65.25054, val_loss: -54.80836, val_recall@20: 0.15362, val_precision@20: 0.04665, val_ndcg@20: 0.1072\n",
            "[Iteration 9000/10000] train_loss: -70.02229, val_loss: -55.11604, val_recall@20: 0.15362, val_precision@20: 0.04665, val_ndcg@20: 0.10725\n",
            "[Iteration 9200/10000] train_loss: -70.4493, val_loss: -55.51435, val_recall@20: 0.15362, val_precision@20: 0.04665, val_ndcg@20: 0.1072\n",
            "[Iteration 9400/10000] train_loss: -67.5873, val_loss: -56.22974, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10726\n",
            "[Iteration 9600/10000] train_loss: -67.99, val_loss: -56.51691, val_recall@20: 0.15362, val_precision@20: 0.04665, val_ndcg@20: 0.10722\n",
            "[Iteration 9800/10000] train_loss: -69.81018, val_loss: -57.40596, val_recall@20: 0.15367, val_precision@20: 0.04675, val_ndcg@20: 0.10726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLcdvV5iXBSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3fa31f06-1c2a-4932-d5f5-83f7585b4d8b"
      },
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UjCTMQ_N5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bb96c7-09b2-4dc4-e591-5a33bf3c7a33"
      },
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -51.54445, test_recall@20: 0.12452, test_precision@20: 0.04665, test_ndcg@20: 0.10127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSFgwnaecWBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20ff0ac-9c17-4f5d-93ac-dc92bd075766"
      },
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: American Beauty (1999), genres: Drama|Romance \n",
            "title: Star Wars: Episode VI - Return of the Jedi (1983), genres: Action|Adventure|Sci-Fi \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n",
            "title: Aladdin (1992), genres: Adventure|Animation|Children|Comedy|Musical \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkRpNldrSQe"
      },
      "source": [],
      "execution_count": 25,
      "outputs": []
    }
  ]
}